import json
import argparse
from bs4 import BeautifulSoup
import re

def parse_schedule(html_file, day_filter=None):
    """
    –ü–∞—Ä—Å–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–∏—á–µ–∫ –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¢—É—Ç—É.—Ä—É
    """
    with open(html_file, 'r', encoding='utf-8') as file:
        html_content = file.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    trains = []
    
    print("üîç –ü–æ–∏—Å–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–∏—á–µ–∫...")
    
    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º
    schedule_rows = soup.find_all('tr', class_='gBhE1wA30JAwoPLW')
    
    print(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {len(schedule_rows)}")
    
    for row in schedule_rows:
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–æ–∫–∏
            row_text = row.get_text(strip=True)
            
            # –ò—â–µ–º –≤—Ä–µ–º—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏—è (—Ñ–æ—Ä–º–∞—Ç –ß–ß:–ú–ú)
            time_match = re.search(r'\b\d{1,2}:\d{2}\b', row_text)
            if not time_match:
                continue
                
            departure_time = time_match.group()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–∞—Ä—à—Ä—É—Ç - —Ç–µ–∫—Å—Ç –º–µ–∂–¥—É –Ω–∞–∑–≤–∞–Ω–∏–µ–º –ø–æ–µ–∑–¥–∞ –∏ –≤—Ä–µ–º–µ–Ω–µ–º/–Ω–æ–º–µ—Ä–æ–º
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —á–∞—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞
            clean_text = re.sub(r'\d{4}', '', row_text)  # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä–∞ –ø–æ–µ–∑–¥–æ–≤
            clean_text = re.sub(r'\b\d{1,2}:\d{2}\b', '', clean_text)  # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º—è
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –∏ –Ω–∞—Ö–æ–¥–∏–º –º–∞—Ä—à—Ä—É—Ç
            parts = clean_text.split()
            route_parts = []
            
            # –ò—â–µ–º —á–∞—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ —Å—Ç–∞–Ω—Ü–∏–∏ (—Å–æ–¥–µ—Ä–∂–∞—Ç –¥–µ—Ñ–∏—Å –∏–ª–∏ –¥–ª–∏–Ω–Ω—ã–µ —Å–ª–æ–≤–∞)
            for part in parts:
                if '-' in part or len(part) > 4:
                    route_parts.append(part)
            
            route = ' '.join(route_parts) if route_parts else "–ú–∞—Ä—à—Ä—É—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–Ω–∏ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            days_info = "–µ–∂–µ–¥–Ω–µ–≤–Ω–æ"
            if '–ë—É–¥–Ω–∏' in row_text:
                days_info = "–±—É–¥–Ω–∏"
            elif '–ï–∂–µ–¥–Ω–µ–≤–Ω–æ' in row_text:
                days_info = "–µ–∂–µ–¥–Ω–µ–≤–Ω–æ"
            elif '–í—ã—Ö–æ–¥–Ω—ã–µ' in row_text or '–°—É–±–±–æ—Ç' in row_text or '–í–æ—Å–∫—Ä–µ—Å–µ–Ω' in row_text:
                days_info = "–≤—ã—Ö–æ–¥–Ω—ã–µ"
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–Ω—è–º
            if day_filter and days_info != day_filter:
                continue
            
            train_info = {
                'departure_time': departure_time,
                'route': route,
                'days': days_info
            }
            
            trains.append(train_info)
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    return trains

def parse_schedule_advanced(html_file, day_filter=None):
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ - –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π
    """
    with open(html_file, 'r', encoding='utf-8') as file:
        html_content = file.read()
    
    soup = BeautifulSoup(html_content, 'html.parser')
    trains = []
    
    # –ò—â–µ–º –≤—Å–µ div –∏ tr —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
    elements = soup.find_all(['div', 'tr'], class_=True)
    
    for element in elements:
        element_text = element.get_text(strip=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º (—Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Ä–µ–º—è –∏ –º–∞—Ä—à—Ä—É—Ç)
        if not re.search(r'\b\d{1,2}:\d{2}\b', element_text):
            continue
            
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        if any(word in element_text for word in ['–ú–∞—Ä—à—Ä—É—Ç', '–û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–î–Ω–∏ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è']):
            continue
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º—è
            time_match = re.search(r'\b\d{1,2}:\d{2}\b', element_text)
            departure_time = time_match.group() if time_match else "00:00"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–∞—Ä—à—Ä—É—Ç - –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –º–µ—Ç–æ–¥
            # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä–∞ –ø–æ–µ–∑–¥–æ–≤, –≤—Ä–µ–º—è –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
            clean_text = re.sub(r'\d{4}', '', element_text)  # –ù–æ–º–µ—Ä–∞ –ø–æ–µ–∑–¥–æ–≤
            clean_text = re.sub(r'\b\d{1,2}:\d{2}\b', '', clean_text)  # –í—Ä–µ–º—è
            clean_text = re.sub(r'\b(–°–ø—É—Ç–Ω–∏–∫|–≠–ª–µ–∫—Ç—Ä–∏—á–∫–∞|–ò–≤–æ–ª–≥–∞|–õ–∞—Å—Ç–æ—á–∫–∞)\b', '', clean_text)  # –¢–∏–ø—ã –ø–æ–µ–∑–¥–æ–≤
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()  # –õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
            
            # –ú–∞—Ä—à—Ä—É—Ç - –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
            route = clean_text if clean_text else "–ú–∞—Ä—à—Ä—É—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–Ω–∏
            days_info = "–µ–∂–µ–¥–Ω–µ–≤–Ω–æ"
            if '–ë—É–¥–Ω–∏' in element_text:
                days_info = "–±—É–¥–Ω–∏"
            elif '–ï–∂–µ–¥–Ω–µ–≤–Ω–æ' in element_text:
                days_info = "–µ–∂–µ–¥–Ω–µ–≤–Ω–æ"
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä
            if day_filter and days_info != day_filter:
                continue
                
            train_info = {
                'departure_time': departure_time,
                'route': route,
                'days': days_info
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π —Ä–µ–π—Å
            if (departure_time != "00:00" and 
                route != "–ú–∞—Ä—à—Ä—É—Ç –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω" and
                len(route) > 5):
                trains.append(train_info)
                
        except Exception as e:
            continue
    
    return trains

def main():
    parser = argparse.ArgumentParser(description='–ü–∞—Ä—Å–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–∏—á–µ–∫')
    parser.add_argument('--filter', choices=['–±—É–¥–Ω–∏', '–µ–∂–µ–¥–Ω–µ–≤–Ω–æ'], 
                       help='–§–∏–ª—å—Ç—Ä –ø–æ –¥–Ω—è–º: –±—É–¥–Ω–∏ –∏–ª–∏ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ')
    
    args = parser.parse_args()
    
    try:
        # –ü—Ä–æ–±—É–µ–º –æ–±–∞ –º–µ—Ç–æ–¥–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
        trains1 = parse_schedule('schedule.html', args.filter)
        trains2 = parse_schedule_advanced('schedule.html', args.filter)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —É–±–∏—Ä–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã
        all_trains = trains1 + trains2
        unique_trains = []
        seen = set()
        
        for train in all_trains:
            key = (train['departure_time'], train['route'])
            if key not in seen:
                seen.add(key)
                unique_trains.append(train)
        
        if not unique_trains:
            print("‚ùå –†–µ–π—Å—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        unique_trains.sort(key=lambda x: x['departure_time'])
        
        print(f"\nüéâ –ù–∞–π–¥–µ–Ω–æ —Ä–µ–π—Å–æ–≤: {len(unique_trains)}")
        if args.filter:
            print(f"üìÖ –§–∏–ª—å—Ç—Ä: {args.filter}")
        print("=" * 70)
        
        for train in unique_trains:
            print(f"‚è∞ {train['departure_time']} | üöÜ {train['route']} | üìÖ {train['days']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        with open('schedule.json', 'w', encoding='utf-8') as f:
            json.dump(unique_trains, f, ensure_ascii=False, indent=2)
            
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ schedule.json")
        
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª schedule.html –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()